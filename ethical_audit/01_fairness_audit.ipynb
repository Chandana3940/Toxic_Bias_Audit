{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "879f81e0-e179-453d-8ad9-b0971a6ba752",
   "metadata": {},
   "source": [
    "Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b4fe89a-5470-4757-ac98-7fb67bc4b353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: C:\\Users\\ual-laptop\\Toxic_Bias_Audit\n",
      "Contents at repo root: ['.git', '.virtual_documents', 'anaconda_projects', 'data', 'Dockerfile', 'environment.yml', 'ethical_audit', 'experiments', 'notebooks', 'README.md', 'report', 'src', 'tests']\n",
      "raw_csv     → C:\\Users\\ual-laptop\\Toxic_Bias_Audit\\data\\raw\\train.csv\n",
      "val_csv     → C:\\Users\\ual-laptop\\Toxic_Bias_Audit\\data\\processed\\val.csv\n",
      "model_path  → C:\\Users\\ual-laptop\\Toxic_Bias_Audit\\experiments\\logreg_multilabel\\logreg_multilabel_tuned.pkl\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup & Imports\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from fairlearn.metrics import (\n",
    "    MetricFrame,\n",
    "    selection_rate,\n",
    "    true_positive_rate,\n",
    "    false_positive_rate,\n",
    "    demographic_parity_difference\n",
    ")\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# We’re in …/Toxic_Bias_Audit/ethical_audit\n",
    "# Go up one level to project root\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.insert(0, repo_root)\n",
    "\n",
    "print(\"Repo root:\", repo_root)\n",
    "print(\"Contents at repo root:\", os.listdir(repo_root))\n",
    "\n",
    "# Define paths\n",
    "raw_csv       = os.path.join(repo_root, 'data', 'raw', 'train.csv')\n",
    "val_csv       = os.path.join(repo_root, 'data', 'processed', 'val.csv')\n",
    "model_path    = os.path.join(repo_root, 'experiments', 'logreg_multilabel', 'logreg_multilabel_tuned.pkl')\n",
    "vectorizer_path = os.path.join(repo_root, 'data', 'processed', 'tfidf.pkl')\n",
    "\n",
    "print(\"raw_csv     →\", raw_csv)\n",
    "print(\"val_csv     →\", val_csv)\n",
    "print(\"model_path  →\", model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30f3527-3593-42a8-8668-41ff8a3b7435",
   "metadata": {},
   "source": [
    "Load Data, Model & Sensitive Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89a8fa0e-b55a-4108-96ba-6fb3043b3c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw columns:\n",
      " ['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
      "\n",
      "Processed val columns:\n",
      " ['comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
      "\n",
      "Using sensitive features: []\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19924\\958177277.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;31m# Cell 2: Load data and determine sensitive-feature columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m# 1. Load the raw dataset to inspect available columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mraw_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_csv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\toxic_bias_audit\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m  10828\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMergeValidate\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10829\u001b[0m     ) -> DataFrame:\n\u001b[0;32m  10830\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10831\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10832\u001b[1;33m         return merge(\n\u001b[0m\u001b[0;32m  10833\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10834\u001b[0m             \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10835\u001b[0m             \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\toxic_bias_audit\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         )\n\u001b[0;32m    169\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         op = _MergeOperation(\n\u001b[0m\u001b[0;32m    171\u001b[0m             \u001b[0mleft_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[0mright_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m             \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\toxic_bias_audit\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    790\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m             \u001b[0mleft_drop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m             \u001b[0mright_drop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 794\u001b[1;33m         ) = self._get_merge_keys()\n\u001b[0m\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mleft_drop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_labels_or_levels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_drop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\toxic_bias_audit\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1306\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mlk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1307\u001b[0m                         \u001b[1;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m                         \u001b[1;31m#  the latter of which will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m                         \u001b[0mlk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1310\u001b[1;33m                         \u001b[0mleft_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1311\u001b[0m                         \u001b[0mjoin_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1312\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m                         \u001b[1;31m# work-around for merge_asof(left_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\toxic_bias_audit\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1907\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1908\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1910\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1911\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1913\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1914\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'id'"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load data and determine sensitive-feature columns\n",
    "\n",
    "# 1. Load the raw dataset to inspect available columns\n",
    "raw_df = pd.read_csv(raw_csv)\n",
    "print(\"Raw columns:\\n\", raw_df.columns.tolist())\n",
    "\n",
    "# 2. Load the processed validation split (with 'id')\n",
    "val_df = pd.read_csv(val_csv)\n",
    "print(\"\\nProcessed val columns:\\n\", val_df.columns.tolist())\n",
    "\n",
    "# 3. Identify identity-related columns in raw_df\n",
    "#    We’ll look for columns that represent demographics or identities:\n",
    "possible_identities = [\n",
    "    'male','female','transgender','other_gender',\n",
    "    'heterosexual','homosexual_gay_or_lesbian',\n",
    "    'christian','jewish','muslim','hindu',\n",
    "    'black','white','psychiatric_or_mental_illness',\n",
    "    'intellectual_or_learning_disability',\n",
    "    'other_race_or_ethnicity'\n",
    "]\n",
    "# Keep only those actually present\n",
    "sens_feats = [c for c in possible_identities if c in raw_df.columns]\n",
    "print(\"\\nUsing sensitive features:\", sens_feats)\n",
    "\n",
    "# 4. Fill missing and merge onto val_df by 'id'\n",
    "raw_df[sens_feats] = raw_df[sens_feats].fillna(0)\n",
    "audit_df = val_df.merge(\n",
    "    raw_df[['id'] + sens_feats],\n",
    "    on='id',\n",
    "    how='left'\n",
    ").fillna(0)\n",
    "\n",
    "# 5. Prepare arrays for the 'toxic' label audit\n",
    "X_val = audit_df['comment_text']\n",
    "y_true = audit_df['toxic']\n",
    "# For demonstration, pick the first sensitive feature if any\n",
    "group_feat = sens_feats[0] if sens_feats else None\n",
    "if group_feat:\n",
    "    group = audit_df[group_feat].astype(int)\n",
    "    print(f\"\\nGrouping by: {group_feat}\")\n",
    "    print(group.value_counts())\n",
    "else:\n",
    "    raise ValueError(\"No sensitive-feature columns found in raw data.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d9f897-f3f6-4b10-8942-e0c851dff4f7",
   "metadata": {},
   "source": [
    "Compute Fairness Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec701207-a9c9-4dec-a99b-e32aedcb3fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose one sensitive feature to demonstrate, e.g. 'male'\n",
    "group = val_with_raw['male'].astype(int)\n",
    "\n",
    "# Build a MetricFrame\n",
    "metrics = {\n",
    "    'accuracy': accuracy_score,\n",
    "    'selection_rate': selection_rate,\n",
    "    'true_positive_rate': true_positive_rate,\n",
    "    'false_positive_rate': false_positive_rate\n",
    "}\n",
    "\n",
    "mf = MetricFrame(\n",
    "    metrics=metrics,\n",
    "    y_true=val_with_raw['toxic'],\n",
    "    y_pred=y_pred,\n",
    "    sensitive_features=group\n",
    ")\n",
    "\n",
    "print(\"=== Overall Metrics ===\")\n",
    "print(mf.overall)\n",
    "print(\"\\n=== By Group ===\")\n",
    "print(mf.by_group)\n",
    "print(\"\\n=== Demographic Parity Difference ===\")\n",
    "print(demographic_parity_difference(\n",
    "    y_true=val_with_raw['toxic'],\n",
    "    y_pred=y_pred,\n",
    "    sensitive_features=group\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07cbf82-a01d-41ca-843d-1bdeba8ba529",
   "metadata": {},
   "source": [
    "Visualize Disparities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e54c146-1e5c-46ae-87f7-2419c37926b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Bar plot of TPR by group\n",
    "mf.by_group['true_positive_rate'].plot(kind='bar', title='TPR by Male=0 vs Male=1')\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.show()\n",
    "\n",
    "# Bar plot of selection rate\n",
    "mf.by_group['selection_rate'].plot(kind='bar', title='Selection Rate by Male=0 vs Male=1')\n",
    "plt.ylabel(\"Selection Rate\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a144419d-c0fe-44b3-b9e6-62ba41444f22",
   "metadata": {},
   "source": [
    "Save Audit Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90027a3-ba84-4e97-a8ad-474061a5c9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = os.path.join(repo_root, 'notebooks', 'ethical_audit', 'results')\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "mf.by_group.to_csv(os.path.join(out_dir, 'fairness_by_group.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (toxic_bias_audit)",
   "language": "python",
   "name": "toxic_bias_audit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
